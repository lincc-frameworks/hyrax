{
    "benchmarks.time_database_connection_help": {
        "code": "def time_database_connection_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for database_connection\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"database_connection\", \"--help\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_database_connection_help",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "074d71554db1f54017ecc860ba5cde2e99fa2d1303d7a726dd672b55e6553c6d",
        "warmup_time": -1
    },
    "benchmarks.time_download_help": {
        "code": "def time_download_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for download\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"download\", \"--help\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_download_help",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "50b3d711c54144a66a40aaf1fdb3fd2d57740df17bc1ee7f6bfbf04334ffbd33",
        "warmup_time": -1
    },
    "benchmarks.time_help": {
        "code": "def time_help():\n    \"\"\"\n    time how long it takes to run --help from the CLI\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"--help\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_help",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "869a14d6a4b498042fb46c6100c1d810a36514446471b46798d86255fce3e355",
        "warmup_time": -1
    },
    "benchmarks.time_import": {
        "code": "def time_import():\n    \"\"\"\n    time how long it takes to import our package. This should stay relatively fast.\n\n    Note, the actual import time will be slightly lower than this on a comparable system\n    However, high import times do affect this metric proportionally.\n    \"\"\"\n    result = subprocess.run([\"python\", \"-c\", \"import hyrax\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_import",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6a64ee071d3191fd146072ef269ea2f274ab7d7e90f8b4958584aa5636e6d64c",
        "warmup_time": -1
    },
    "benchmarks.time_infer_help": {
        "code": "def time_infer_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for infer\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"infer\", \"--help\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_infer_help",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "3d49904114f6a63a32cf099bf9a4fb986de4285df6eddc0a5ea855effcf3fb25",
        "warmup_time": -1
    },
    "benchmarks.time_lookup_help": {
        "code": "def time_lookup_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for lookup\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"lookup\", \"--help\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_lookup_help",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "12248d850368f773ddf88f0c779d8a1090f15b753675c3b607339ddd8d0d5e4a",
        "warmup_time": -1
    },
    "benchmarks.time_nb_obj_construct": {
        "code": "def time_nb_obj_construct():\n    \"\"\"\n    time how long notebook users must wait for our interface object to construct\n    \"\"\"\n    hyrax.Hyrax()",
        "min_run_count": 2,
        "name": "benchmarks.time_nb_obj_construct",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "5fa120dae3cc7ce68885b5098a7d010151c4f44a4c46acba2b536e55775aa8b8",
        "warmup_time": -1
    },
    "benchmarks.time_nb_obj_dir": {
        "code": "def time_nb_obj_dir():\n    \"\"\"\n    Time how long it takes to construct the interface object and load the\n    dynamcally generated list of verbs using `dir()`\n    \"\"\"\n    h = hyrax.Hyrax()\n    dir(h)",
        "min_run_count": 2,
        "name": "benchmarks.time_nb_obj_dir",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "f8b0daee1ef646aaea154b1ee9e661ce586b1b0073b2e26bd9fdf014c98c2f21",
        "warmup_time": -1
    },
    "benchmarks.time_prepare_help": {
        "code": "def time_prepare_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for prepare\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"prepare\", \"--help\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_prepare_help",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "586a018de0f515b9d5576edf77a70be08d6e14757b282e8408cfdae3f2321d98",
        "warmup_time": -1
    },
    "benchmarks.time_rebuild_manifest_help": {
        "code": "def time_rebuild_manifest_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for rebuild_manifest\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"rebuild_manifest\", \"--help\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_rebuild_manifest_help",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "75c72b4d902276b452aa080d05007fde289454004542bd926c0a1bac4190eb0d",
        "warmup_time": -1
    },
    "benchmarks.time_save_to_database_help": {
        "code": "def time_save_to_database_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for save_to_database\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"save_to_database\", \"--help\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_save_to_database_help",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "a64a33bc999da1f4ae4d41b65038c9e29bb55b1fab9ec95f04c1b3b1d2c1f21d",
        "warmup_time": -1
    },
    "benchmarks.time_train_help": {
        "code": "def time_train_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for train\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"train\", \"--help\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_train_help",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "6e3bccf7cc8666d49e9fd52838e601745f958f6fdefd66252020cf38ede4320c",
        "warmup_time": -1
    },
    "benchmarks.time_umap_help": {
        "code": "def time_umap_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for umap\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"umap\", \"--help\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_umap_help",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "e76c6a5f58d7e66a935f286d9afecfff64edd2df937f33f74fbbc9a433f08e58",
        "warmup_time": -1
    },
    "benchmarks.time_visualize_help": {
        "code": "def time_visualize_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for visualize\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"visualize\", \"--help\"])\n    assert result.returncode == 0",
        "min_run_count": 2,
        "name": "benchmarks.time_visualize_help",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "c3ea3d131fe20f6e7d7b727c7b7f0b76b1502499687ec0b17a4924e50925f09b",
        "warmup_time": -1
    },
    "data_request_benchmarks.DatasetRequestBenchmarks.time_request_all_data": {
        "code": "class DatasetRequestBenchmarks:\n    def time_request_all_data(self):\n        \"\"\"Benchmark the amount of time needed to retrieve all the data from\n        the random dataset\n        \"\"\"\n        for indx in self.indexes:\n            self.ds[indx]\n\n    def setup(self):\n        \"\"\"Prepare for benchmark by defining and setting up a random dataset\"\"\"\n        self.tmp_dir = tempfile.TemporaryDirectory()\n        self.input_dir = Path(self.tmp_dir.name)\n    \n        self.h = Hyrax()\n        self.h.config[\"general\"][\"results_dir\"] = str(self.input_dir)\n        self.h.config[\"model_inputs\"] = {\n            \"data\": {\n                \"dataset_class\": \"HyraxRandomDataset\",\n                \"data_location\": str(self.input_dir),\n                \"fields\": [\"image\", \"label\", \"object_id\"],\n            }\n        }\n    \n        num_vectors = 4096\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"size\"] = num_vectors\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"seed\"] = 0\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"shape\"] = [3, 64, 64]\n    \n        self.ds = self.h.prepare()\n    \n        self.indexes = np.random.randint(0, num_vectors, size=128, dtype=int)",
        "min_run_count": 2,
        "name": "data_request_benchmarks.DatasetRequestBenchmarks.time_request_all_data",
        "number": 0,
        "param_names": [],
        "params": [],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "type": "time",
        "unit": "seconds",
        "version": "fb29c4de00b8ae98f5355bc0763d7785b2a711282021eb0d6b2065d2f426f355",
        "warmup_time": -1
    },
    "vector_db_benchmarks.VectorDBInsertBenchmarks.peakmem_load_vector_db": {
        "code": "class VectorDBInsertBenchmarks:\n    def peakmem_load_vector_db(self, vector_length, vector_db_implementation):\n        \"\"\"Memory benchmark for loading a vector database.\"\"\"\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            self.h.save_to_database(output_dir=Path(tmp_dir))\n\n    def setup(self, vector_length, vector_db_implementation):\n        \"\"\"Set up for vector database benchmarks. Create a temporary directory,\n        configure Hyrax with a loopback model, and generate a random dataset, run\n        inference to create the result files for insertion into the vector database.\"\"\"\n        self.tmp_dir = tempfile.TemporaryDirectory()\n        self.input_dir = Path(self.tmp_dir.name)\n    \n        self.h = Hyrax()\n        self.h.config[\"general\"][\"results_dir\"] = str(self.input_dir)\n        self.h.config[\"model_inputs\"] = {\n            \"data\": {\n                \"dataset_class\": \"HyraxRandomDataset\",\n                \"fields\": [\"image\", \"label\", \"object_id\"],\n                \"primary_id_field\": \"object_id\",\n            }\n        }\n        self.h.config[\"model\"][\"name\"] = \"HyraxLoopback\"\n    \n        # Default inference batch size is 512, so this should result in 4 batch files\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"size\"] = 2048\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"seed\"] = 0\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"shape\"] = [vector_length]\n    \n        # Qdrant requires the vector size in order to create its collections\n        self.h.config[\"vector_db\"][\"qdrant\"][\"vector_size\"] = vector_length\n    \n        weights_file = self.input_dir / \"fakeweights\"\n        with open(weights_file, \"a\"):\n            pass\n        self.h.config[\"infer\"][\"model_weights_file\"] = str(weights_file)\n    \n        self.h.config[\"vector_db\"][\"name\"] = vector_db_implementation\n    \n        self.h.infer()",
        "name": "vector_db_benchmarks.VectorDBInsertBenchmarks.peakmem_load_vector_db",
        "param_names": [
            "vector_length",
            "vector_db_implementation"
        ],
        "params": [
            [
                "64",
                "256",
                "2048",
                "16384"
            ],
            [
                "'chromadb'",
                "'qdrant'"
            ]
        ],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "43060773e49b74dbe0628d635584f44aa12d69def9df7a718f2919f833b6fdd3"
    },
    "vector_db_benchmarks.VectorDBInsertBenchmarks.time_load_vector_db": {
        "code": "class VectorDBInsertBenchmarks:\n    def time_load_vector_db(self, vector_length, vector_db_implementation):\n        \"\"\"Timing benchmark for loading a vector database.\"\"\"\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            self.h.save_to_database(output_dir=Path(tmp_dir))\n\n    def setup(self, vector_length, vector_db_implementation):\n        \"\"\"Set up for vector database benchmarks. Create a temporary directory,\n        configure Hyrax with a loopback model, and generate a random dataset, run\n        inference to create the result files for insertion into the vector database.\"\"\"\n        self.tmp_dir = tempfile.TemporaryDirectory()\n        self.input_dir = Path(self.tmp_dir.name)\n    \n        self.h = Hyrax()\n        self.h.config[\"general\"][\"results_dir\"] = str(self.input_dir)\n        self.h.config[\"model_inputs\"] = {\n            \"data\": {\n                \"dataset_class\": \"HyraxRandomDataset\",\n                \"fields\": [\"image\", \"label\", \"object_id\"],\n                \"primary_id_field\": \"object_id\",\n            }\n        }\n        self.h.config[\"model\"][\"name\"] = \"HyraxLoopback\"\n    \n        # Default inference batch size is 512, so this should result in 4 batch files\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"size\"] = 2048\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"seed\"] = 0\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"shape\"] = [vector_length]\n    \n        # Qdrant requires the vector size in order to create its collections\n        self.h.config[\"vector_db\"][\"qdrant\"][\"vector_size\"] = vector_length\n    \n        weights_file = self.input_dir / \"fakeweights\"\n        with open(weights_file, \"a\"):\n            pass\n        self.h.config[\"infer\"][\"model_weights_file\"] = str(weights_file)\n    \n        self.h.config[\"vector_db\"][\"name\"] = vector_db_implementation\n    \n        self.h.infer()",
        "min_run_count": 2,
        "name": "vector_db_benchmarks.VectorDBInsertBenchmarks.time_load_vector_db",
        "number": 0,
        "param_names": [
            "vector_length",
            "vector_db_implementation"
        ],
        "params": [
            [
                "64",
                "256",
                "2048",
                "16384"
            ],
            [
                "'chromadb'",
                "'qdrant'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "26b5efa8b1788a24a9b67259690620b220a3109ac99428cc800e8f7e4c280362",
        "warmup_time": -1
    },
    "vector_db_benchmarks.VectorDBSearchBenchmarks.peakmem_search_by_vector_many_shards": {
        "code": "class VectorDBSearchBenchmarks:\n    def peakmem_search_by_vector_many_shards(self, shard_size_limit, vector_db_implementation):\n        \"\"\"Benchmark memory to perform a search by ID on a dataset with many shards.\"\"\"\n        self.db.search_by_vector(self.data_sample, k=1)\n\n    def setup(self, shard_size_limit, vector_db_implementation):\n        \"\"\"Set up for vector database benchmarks. Create a temporary directory,\n        configure Hyrax with a loopback model, and generate a random dataset, run\n        inference to create the result files for insertion into the vector database.\"\"\"\n        self.tmp_input_dir = tempfile.TemporaryDirectory()\n        self.tmp_output_dir = tempfile.TemporaryDirectory()\n        self.input_dir = Path(self.tmp_input_dir.name)\n        self.output_dir = Path(self.tmp_output_dir.name)\n    \n        self.vector_length = 1024\n    \n        self.h = Hyrax()\n        self.h.config[\"general\"][\"results_dir\"] = str(self.input_dir)\n        self.h.config[\"model_inputs\"] = {\n            \"data\": {\n                \"dataset_class\": \"HyraxRandomDataset\",\n                \"fields\": [\"image\", \"label\", \"object_id\"],\n                \"primary_id_field\": \"object_id\",\n            }\n        }\n        self.h.config[\"data_loader\"][\"batch_size\"] = 4096\n        self.h.config[\"model\"][\"name\"] = \"HyraxLoopback\"\n    \n        # Default inference batch size is 512, so this should result in 4 batch files\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"size\"] = 4096\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"seed\"] = 0\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"shape\"] = [1024]\n    \n        # Create a fake weights file and then run inference on the random dataset\n        weights_file = self.input_dir / \"fakeweights\"\n        with open(weights_file, \"a\"):\n            pass\n        self.h.config[\"infer\"][\"model_weights_file\"] = str(weights_file)\n    \n        self.h.infer()\n    \n        # Get the list of dataset ids\n        self.ds = self.h.prepare()\n        self.data_sample = self.ds[0][\"data\"][\"image\"]\n    \n        self.h.config[\"vector_db\"][\"name\"] = vector_db_implementation\n        self.h.config[\"vector_db\"][\"chromadb\"][\"shard_size_limit\"] = shard_size_limit\n        # Qdrant requires the vector size in order to create its collections\n        self.h.config[\"vector_db\"][\"qdrant\"][\"vector_size\"] = self.vector_length\n    \n        # Save inference results to vector database and create a db connection\n        self.h.save_to_database(output_dir=Path(self.output_dir))\n        self.db = self.h.database_connection(self.output_dir)",
        "name": "vector_db_benchmarks.VectorDBSearchBenchmarks.peakmem_search_by_vector_many_shards",
        "param_names": [
            "shard_size_limit",
            "vector_db_implementation"
        ],
        "params": [
            [
                "64",
                "128"
            ],
            [
                "'chromadb'",
                "'qdrant'"
            ]
        ],
        "timeout": 120,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "21999ca94ead35b32d4eb4221cbe26fb1abc43715d5318cf7a3f033925a84bbe"
    },
    "vector_db_benchmarks.VectorDBSearchBenchmarks.time_search_by_vector_many_shards": {
        "code": "class VectorDBSearchBenchmarks:\n    def time_search_by_vector_many_shards(self, shard_size_limit, vector_db_implementation):\n        \"\"\"Benchmark timing to perform a search by ID on a dataset with many shards.\"\"\"\n        self.db.search_by_vector(self.data_sample, k=1)\n\n    def setup(self, shard_size_limit, vector_db_implementation):\n        \"\"\"Set up for vector database benchmarks. Create a temporary directory,\n        configure Hyrax with a loopback model, and generate a random dataset, run\n        inference to create the result files for insertion into the vector database.\"\"\"\n        self.tmp_input_dir = tempfile.TemporaryDirectory()\n        self.tmp_output_dir = tempfile.TemporaryDirectory()\n        self.input_dir = Path(self.tmp_input_dir.name)\n        self.output_dir = Path(self.tmp_output_dir.name)\n    \n        self.vector_length = 1024\n    \n        self.h = Hyrax()\n        self.h.config[\"general\"][\"results_dir\"] = str(self.input_dir)\n        self.h.config[\"model_inputs\"] = {\n            \"data\": {\n                \"dataset_class\": \"HyraxRandomDataset\",\n                \"fields\": [\"image\", \"label\", \"object_id\"],\n                \"primary_id_field\": \"object_id\",\n            }\n        }\n        self.h.config[\"data_loader\"][\"batch_size\"] = 4096\n        self.h.config[\"model\"][\"name\"] = \"HyraxLoopback\"\n    \n        # Default inference batch size is 512, so this should result in 4 batch files\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"size\"] = 4096\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"seed\"] = 0\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"shape\"] = [1024]\n    \n        # Create a fake weights file and then run inference on the random dataset\n        weights_file = self.input_dir / \"fakeweights\"\n        with open(weights_file, \"a\"):\n            pass\n        self.h.config[\"infer\"][\"model_weights_file\"] = str(weights_file)\n    \n        self.h.infer()\n    \n        # Get the list of dataset ids\n        self.ds = self.h.prepare()\n        self.data_sample = self.ds[0][\"data\"][\"image\"]\n    \n        self.h.config[\"vector_db\"][\"name\"] = vector_db_implementation\n        self.h.config[\"vector_db\"][\"chromadb\"][\"shard_size_limit\"] = shard_size_limit\n        # Qdrant requires the vector size in order to create its collections\n        self.h.config[\"vector_db\"][\"qdrant\"][\"vector_size\"] = self.vector_length\n    \n        # Save inference results to vector database and create a db connection\n        self.h.save_to_database(output_dir=Path(self.output_dir))\n        self.db = self.h.database_connection(self.output_dir)",
        "min_run_count": 2,
        "name": "vector_db_benchmarks.VectorDBSearchBenchmarks.time_search_by_vector_many_shards",
        "number": 0,
        "param_names": [
            "shard_size_limit",
            "vector_db_implementation"
        ],
        "params": [
            [
                "64",
                "128"
            ],
            [
                "'chromadb'",
                "'qdrant'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 120,
        "type": "time",
        "unit": "seconds",
        "version": "da3e4cae8178e77d6b0575a625b82fc74129f2bad3592831b6c37b91912ed4a0",
        "warmup_time": -1
    },
    "version": 2
}