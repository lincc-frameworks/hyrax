{"project": "hyrax", "project_url": "https://github.com/lincc-frameworks/hyrax", "show_commit_url": "https://github.com/lincc-frameworks/hyrax/commit/", "hash_length": 8, "revision_to_hash": {"0": "fed5f877b5aae17adb85ab712f969a7f4f2f2180", "3": "88bd67ecae363284a6fe4a669317372878eda019", "4": "cf6aade933ea8ae6e130208995da6a2e45999cb4", "5": "2d5c9a5c5e092cad42ca9eb5f181c0d4ea6226b2", "9": "0cd1e6cf921c1b5ad22359f9a5f0e199d6c9bebf", "12": "827babfd6b396e438701c7b07861687c76f2d02a", "13": "b66d834e71d32210127e1617cbb4699afdb176ba", "14": "1615ee680890df832e207d0017d8422367d0b435", "15": "7bfb7dbf1ad0bda41b114f6ffdcb6d2dc77f41b2", "16": "fc2b8dbf717c1e165d53b9b06451f9e0362d1e4b", "17": "fe75ed4c16811cd99d14b5a642a5045a2993571c", "18": "ad62eb0c05cd61ae39339081aea48fe058cb73c2", "19": "d92ffff030751874e94ee712e41739a6f6249451", "20": "28c3eb4a39e8a3226669a298b339f6deb6306cb4", "21": "161b80605421bb82c5cd8f3e3b4720b33271b403", "26": "cab9515792201b5f894279bad36f73afdf9b3ba6", "31": "83071e937e05a6496805e22dd8bd7484e51ac4ca", "32": "02df7b5f3f41bc9d3fab737ffccbbf4f7ca747be", "35": "79293c8201d476d6994bc545db8694bca8044a8a", "40": "f5b57dabe6cac8d47d7e1834b10889ad0222edd6", "41": "eec383c243e42fa151d434b7cb484c5aa20d5c7f", "42": "2fb04de084b27bcebe77bd47f7fd8ecaab8d457c", "47": "000c5651ba5c44b1e50977d1c0d3a8434afe73c2", "48": "fde4c18a3938f20e90524c7a4b709fab78ef5b40", "49": "3ee838057b116442495a3cfc4bb6adef4ad98a5b", "50": "c8c433f11a4605ff5c0f7b3314c5dafb5e98e6a8", "51": "2fb3a749892f021fcf40fc66be5e40dc0a87eb52", "52": "a72381234d0c2163b38d80c921923712f36e3e4d", "53": "a8ef50fde556b69ede5c51b85a0a0b1386c08279", "54": "bd30681c410fd76d81d0d2db2f8524e2e3e56ea7", "55": "734a4e21761f4ecd8e4101b2a90c520f38de0df8", "56": "5b601db8c72e58e80a346653217d51577b2128fc", "57": "d2048f75270b855a921f9781f90684609ad2eba5", "58": "8ca2e8f1fa4173addc9f693a0aeeea24e8ef041b", "64": "55cc2cf43262977434bca2d4b248123b6f4e25b6", "65": "6207ebc8904fa859c4bea22e9f9a0f9436d225f8", "66": "3068b8f745e5c7e6dbae3b8aa6255b6dc8e66810", "67": "6b8d97883cf95829c2e8ef4e0aebab5227c3f4f7", "68": "24f2f510ab5c8b7f6cdc990bc9f243ec032df026", "69": "de913893723207249a926cfa674feccbaec9e84f", "70": "dad7062041b6cc053cbe29bf9a6efe0424cdeb21", "71": "cefda8797f73014de5865a49def0778a064cf02d", "72": "16a6b688590c503e01c60755687f8c2e391449b9", "73": "b504b62d44a9af8b1ad7357424398a8ed1f2fbe0", "74": "ea42b171444f8455c4a66c6846bd0da46ece6304", "75": "c12e7d5223e9b2a4226381feb7f0f623031c8e7c", "77": "b0bcf004269b282be8501cef2a1b1f74c6fbd300", "78": "c2e32c7f8a4f67fe320cfb4a200e5f4c03a2a9cf", "79": "e666dbe78111786d278b52772ca2b9668eb23254", "80": "4d878a9c0910178e2b13b1b6ac3a96f638279171", "81": "ae484c1888aa767f2f7b0ccb6069e08142b663e7", "82": "4eb83019aa880b003fb1e625aa746af62f9fb185", "84": "7b3b99274a78a13510107f06c14e8245ac7fef5b", "85": "0467d4a1919faee002abc2096108466c32097883", "89": "e6158115c60586a41ba7aa0ed8362b0216bd40c1", "93": "2fa8aa31d202999a6f496adc822fcaa4e3c5ca5b", "94": "a8d6600793c4989b452e12a50e3670d6c1ba78d2", "95": "02c756117936acc1f4194502cd172ac095657513", "96": "cc2f12bcaeefe6d1fe2609ab8826be0fc23f47c7", "104": "4d60235137d64b454b93056037d901853194960e", "105": "3ac3130eb1cc6a54170b8c73c765004bc0c37407", "106": "677bd7036f19a827b1da13054daab4c4ae47a59b", "107": "10061e13790e213dfffd0dbf1a807e12e768e2ed", "108": "7e12933d5ca4a8d3c4ae085946f23af65b397c59", "109": "aaccba06c6659a0672661a9a656c52e3ce23ba0e", "111": "9d1fb12a0a9b6bcc1bfda360ead06bdd2d08c89d", "112": "72d4590bd3da3ab5d2ce0bc5af0ad772b49af8fb", "113": "6eb3bb0ee35d2589623747c467be58904071f6ed", "114": "9ee75ce43ff96f47466f7779b96762b8f83e0bc6", "115": "3a202921fefb457f125d2546e6ec469cd5194a36", "116": "da9ed0ab83602eba34d1cca81634c0291219401c", "119": "91eb459cf69b2945c187d7bab074963763b00384", "121": "c86ab5e70780a32c11d50350e0d6dbd72e59e59c", "122": "11a235a96ee62b58f02d248ba576e9e756d4b83a", "125": "d7456947db5e64d2553a9e7162adf16cc90d3a4a", "126": "86ff5fbe9ce8da45857306d3ee28c515f28960f3", "127": "f579280f728ebcd72ba7a91b392eda5ae96496f9", "128": "b1100f5af3f6750754b4014e91cc0f811c957ce7", "129": "e3c94af392d5bc1e2124b73606fa228ac4a8c9a6", "130": "839cf98da85a01e03b37cf5995d342ebc1d8f518", "131": "c829885f583166762bfeb5c2d8a460b26dbb8b5e", "132": "50ba38733f361bc2fcc94163e1db1df12afebff0", "133": "9b5773238b09a3d2108c84a9c4883e1fa6c364b8", "134": "fa3a72648b010356b9e01cd6a1c7837740dce4bb", "135": "e78f470c61979c6d6ce2a6303bd6d3e74dcfba88", "136": "0cfbc26ed91790bfc990935098737052a0639124", "137": "5d38be5b6aaef8bebccfbdede5c6b533b5919ba2", "139": "7fe5a23d3898f9e09cc99328b09cd24e9093b74f", "141": "78d0af655e24545a2c418c2299dcde295d1de53d", "142": "d4127e19e69ff6f715e1dd019aa7c51711a9ff1a", "143": "a0281e9d60733b37638e8a0a6a5b89a948a2477b", "144": "495321b937a257b498c67e99b5eccc9b88850c06", "148": "79326f8f83eb7210c16a5ad79c4968ccf80e85e8", "149": "5ac6e2e45b7a7a581501501c60ea609ac1f8f225", "153": "de484932e99685cb0b070de6de35aeb2846683e7", "154": "8ebf0c34c23900f4d3b9c31428158510db4b7ac3", "155": "24de59c2c3e53928d68b24aa6b1f527c0dd76692", "156": "8b204b5329a8048394a3a52175c2f4ad13e6d7d5", "157": "f9ea911d7cefd5cc5e2d9d68dd234c8c936ef092", "158": "0c9981696b479216d31fc79f4d8643cdc41b7e92", "159": "2356b0af7bbfd68dc02516cf828d83347c2145ed", "160": "76446219365e2f4ed9f70cd04c4c8ed96d91aa55", "161": "d5d1e45cd3a409d5ce017cf407cd37090b0acc6e", "162": "32a062bf0dba2b6b6411b05d434ac05db7e5503f", "163": "9bc0baeb5d8aeed4008208abaf5862ce54244e7b", "168": "6662654e20be5e1e4c322b63f587f56b89b30c44", "169": "785565ee9f0905a7989b5694445d888068e3c9bb", "170": "dd29368839f3c9e5fded3c7d43c7f3a4e2278452", "171": "4159efcfe5cbecaef5fb75cf7b68722d44463408", "172": "6dcc664a8e7d09584b30b352bf6d4dec1b9d14d0", "173": "99b964658a41aba14d4566fa60a88d6eec9b5605", "174": "3b492eea1032c896bb804a7949d7d7504a9a910a", "175": "b26a71d127537c842267a3fafdc131ff5d4abbdb", "176": "497801b4d096ca8ae76bd8087d0f924fe9c4a0cd", "177": "d943803d920e8286cf9d96ce6500a33c12c0693c", "179": "923ad47009db3933a3e83ddfe84d408028dcc820", "180": "acb9deaf1bf72c7e1a5d976f395b6db2277e9665", "181": "4a39ca1242fd6d3d21914dd69d5b7cc1d5f9e227", "183": "5d575e4ccb2e95537366406be3c79a4a799aedd7", "184": "fe0ef6df585920348ebf40a39f9686113e971e56", "185": "1f946e86d88f8af7fb7d7091e6477dca87fdb72f", "186": "ee3fe2805d5c23a80c2f30ce28c7104b96533895", "187": "0998d614d65e51100f68ebcc72243ae7ea5e77dd", "189": "d30468b9161de57fd609c4be300be7b968b7061a", "190": "aca2e323ff8c646d9918ea43f5d7abe77b715d6c", "191": "9d03e928569293b86dd9d010e63819a1c42f78d3", "192": "191a12fbb775a1da6994f669d681d1f51e559633", "193": "cfde4a0490b2eeb94992e1a4752d664a27f2363d", "194": "91bf6ffb9ae60a8f806df0970c5902532ce8bf97", "195": "b5bb8f7f7d844d703aefbdf9a89d8c0f51a4c64a", "197": "74c98057f396a2dd80c08a95576501115f030c4b", "198": "fee6355fbc51bddb2c73ae3016c28ca6d0be2e72", "199": "d5a8d7fdf62243d76c7188e803822153f19ea446", "205": "615b6a37249ed9951a23528abab931c915727143", "206": "3c6e9ec40fd024439c964a5fba9d30cb7172f174", "208": "33cf79329ad7723ed7547f1df8748f78bf64fd02", "210": "569b98cc335d8fc1753bbd86288c50e4737bc68a", "211": "990bfa0f94700e94ac8efa65e7f8462b8b1a7900", "213": "3a56a04a2d994ad4e2b86b743840543745b2b311", "218": "1edbc345fdcb8748c4ebd0e618519b749efd8b8f", "219": "82436c8a2b6b8eb85b9a574d944a176bcb287364", "220": "301d081f1656be73ecb947bddd8800147c6941d6", "223": "01b735437bfbb5ea6c0bae87b2252c0e349c5e68", "225": "78240e28f15b481aee442644d382ea6c01496f06", "227": "6f7bcf43acb84d3e43178d2f35bbd0bda2e3e8bd", "228": "c2145b78073b85f586b2ff0aa7325a568913e107", "237": "f1198108886714fc386f3fc440c1766775fcd7c7", "239": "81ad2adf57aacfab6fc7e0c2f8f91f351c79e2b9", "240": "2a4bc122216994d0d5d8140b769e3f3da83b8ee3", "243": "85e53ce3434e4695d509414a74ed8f8b00520ed1", "244": "417c2291a29969f5ba9f422879890d956ad543a4", "245": "1ea3615e2d4fb9bf38644a674752bd5363dae277", "246": "7db656d389f361d1fee0bd67c43b0f97476b6428", "247": "fa8b81585a6e90c15170be2b6fc08884b15f4463", "248": "472794e1baf5433254c14de79cf38674f4a93fbe", "249": "c8c1d8c6eaedb9223c73a2d3655d227d66c98824", "250": "f8bb684fb6e46fe4f2fa7e8daa044285572a1f8f", "251": "f3f1c6681b2c58a88c48df4fe951f8ec49cdc70b", "252": "7f72349ef20aa2c33314cff505725f0eabc867d4", "253": "74bb4b0babb76e302869479b76c037f9f9dfd5e2", "255": "680b33499ca85c2d8b725d7de1318f197a77d616", "256": "14d930e7736259f8e9923169ca37484ec4b127c5", "257": "89050b0d55d5e354467213f883cbca86018de96f", "262": "848d7d9e089b402b439a152b9809c0acd31e01c0", "263": "f644a1ac0836a4a6c425727da6dc4ffcf5847556", "265": "8e6c67d263038ba521b3777aed2d760265480f48", "267": "f4fd823839a7dadf978ef93e58245222df723380", "268": "e4a6eb975ef66fda1c3c5c60fb2115ccf887c576", "269": "12b931836632c471e7f1de6075d2cd5b5ec22f82", "271": "ae0398b09d01e618165eb4d9a9355b2c45af4c20", "272": "e42e5e085ef25accd8ac26d2303430396e037199", "273": "009b52382498f6030506be0fdf7b5fa591f6f7f8", "274": "7bc2419ccfb8d6d80ca4e2771e86cdb6af53e210", "275": "ff80b62685fa9105b14c5ebdac53466720ec9bf8", "279": "bb6f9ea32e8ba545fc4910488ba424ad6f0dc8d0", "280": "82cbc908fb69e3672680873b5957b6c773ad9a54", "281": "a9ace1c336c979ad14cb7eb5572fdba568190fd1", "282": "ed9cfe1006d1b64f7b08b405f5e0168f7a428a20", "283": "901ccc7a0c66a94ed7ebbf90b8ca735641c60949", "284": "1d612f339f3ad869efd7c3f9a6a083ccb073c379", "287": "b00517b396553ddf33589bbdd08f3031b5e36066", "288": "745cabf2d656e0d151dc50107b1ce79001e41f55", "290": "d37672362716fd1790fab38b0800fb82216630da", "292": "904d53c1724f053e40f3a0f3c8983b5b379485d9", "293": "727141738a83cd47cabd11f1c4d8215e608e512a", "298": "64075db412908893f3f9f08578b07e477c7987ce", "299": "642e997062730ab21ce50298dd4bbe9d3a93125f", "302": "370f2e41a3906af1b72737ffd5153b52a5f4f159", "304": "02a6030910a77bb1aa6376c36e53c3d048009fd1", "305": "084e41bc1da1937337ad972c25d33af753e332ce", "312": "66aab00974437940b2ff4d8550f52e665a81e509", "313": "8322c30e9183661c8c69a4dd1ff033fc231761e0", "314": "da513c09906501d91caa2572145c79a520142bfd", "315": "56ae5fc3bbbbb649180db28e95b1e29f4400990a", "317": "e9c7bc45254c37256460782403e21f55129fd39d", "318": "ed4e145186d3eeaddfa6e787a3144522b458c5e6", "319": "5a807ecc4cf4f7c7ec7a2f2e4916f4259cc859ee", "321": "37c9936ea73d8abaf04e07c0358df17c6a1f86d9", "322": "821feab8bdae7885d2b82a05b7963a2fed511c14", "323": "beb806a0979f1dd47259a3e6c331e3ebb0526a6c", "324": "5bccee43044b6662eb2e29dc549b58d8c6e4a92a", "326": "93366bf6de9890504b2025263e20bdd2f3aceb63"}, "revision_to_date": {"0": 1722552502000, "3": 1722553693000, "4": 1722554259000, "5": 1723090707000, "9": 1723486025000, "12": 1723497397000, "13": 1723504853000, "14": 1723661584000, "15": 1723673984000, "16": 1723691212000, "17": 1723744795000, "18": 1723837154000, "19": 1723846450000, "20": 1723847908000, "21": 1724357071000, "26": 1724447502000, "31": 1724784333000, "32": 1724784360000, "35": 1724785749000, "40": 1724955141000, "41": 1724955162000, "42": 1724955456000, "47": 1725903751000, "48": 1725907024000, "49": 1726085246000, "50": 1726598569000, "51": 1726677460000, "52": 1726693515000, "53": 1726856393000, "54": 1727217953000, "55": 1727221219000, "56": 1727481011000, "57": 1727813987000, "58": 1727821954000, "64": 1728341819000, "65": 1728359837000, "66": 1728421680000, "67": 1728426296000, "68": 1728683654000, "69": 1729000693000, "70": 1729000969000, "71": 1729724619000, "72": 1729633258000, "73": 1729806866000, "74": 1729829690000, "75": 1730266772000, "77": 1730823105000, "78": 1730832173000, "79": 1731092515000, "80": 1731528797000, "81": 1731711405000, "82": 1732057382000, "84": 1732332695000, "85": 1733341578000, "89": 1733591133000, "93": 1733788919000, "94": 1733788944000, "95": 1733788954000, "96": 1733958813000, "104": 1734030864000, "105": 1734121466000, "106": 1734373721000, "107": 1736203653000, "108": 1736287112000, "109": 1736548648000, "111": 1736550172000, "112": 1736793601000, "113": 1736793631000, "114": 1736793814000, "115": 1736796621000, "116": 1736979721000, "119": 1736985154000, "121": 1737051016000, "122": 1737051613000, "125": 1737096905000, "126": 1737516734000, "127": 1737570069000, "128": 1737573389000, "129": 1737582853000, "130": 1737585425000, "131": 1737611626000, "132": 1737667154000, "133": 1738347495000, "134": 1738621669000, "135": 1738622274000, "136": 1738699745000, "137": 1738703659000, "139": 1738716784000, "141": 1738785167000, "142": 1738804272000, "143": 1738877493000, "144": 1738891690000, "148": 1738987327000, "149": 1739047122000, "153": 1739218359000, "154": 1739243752000, "155": 1739383097000, "156": 1739394284000, "157": 1739574250000, "158": 1740158160000, "159": 1740441068000, "160": 1740516056000, "161": 1740528824000, "162": 1740532628000, "163": 1741038594000, "168": 1742500846000, "169": 1742576897000, "170": 1742588512000, "171": 1742588949000, "172": 1742840690000, "173": 1742842255000, "174": 1742845018000, "175": 1742856506000, "176": 1742856896000, "177": 1742935408000, "179": 1742953861000, "180": 1743046989000, "181": 1743105405000, "183": 1743178707000, "184": 1743188421000, "185": 1743201967000, "186": 1743442922000, "187": 1743455177000, "189": 1743525403000, "190": 1743633354000, "191": 1743795535000, "192": 1744038824000, "193": 1744142756000, "194": 1744305811000, "195": 1744396636000, "197": 1744837901000, "198": 1744918952000, "199": 1744923324000, "205": 1745016250000, "206": 1745016582000, "208": 1745245833000, "210": 1745356817000, "211": 1745357956000, "213": 1745365818000, "218": 1745434016000, "219": 1745441692000, "220": 1745533682000, "223": 1745954637000, "225": 1745955906000, "227": 1746064099000, "228": 1746064131000, "237": 1746401875000, "239": 1746485387000, "240": 1746486284000, "243": 1746512821000, "244": 1746554409000, "245": 1746569827000, "246": 1746573177000, "247": 1746641064000, "248": 1746658453000, "249": 1746836123000, "250": 1747087993000, "251": 1747330254000, "252": 1747345761000, "253": 1747351732000, "255": 1747782451000, "256": 1747801549000, "257": 1747849284000, "262": 1748387551000, "263": 1748886691000, "265": 1748905924000, "267": 1748909161000, "268": 1748918488000, "269": 1749060712000, "271": 1749161175000, "272": 1749750744000, "273": 1750456303000, "274": 1750471342000, "275": 1750714217000, "279": 1751159869000, "280": 1751487274000, "281": 1751487317000, "282": 1751519077000, "283": 1751992957000, "284": 1751999205000, "287": 1752089180000, "288": 1752167220000, "290": 1752175281000, "292": 1752521798000, "293": 1752528218000, "298": 1752612734000, "299": 1752612764000, "302": 1752794030000, "304": 1752879369000, "305": 1753133304000, "312": 1754116700000, "313": 1755033368000, "314": 1755532927000, "315": 1755544126000, "317": 1755708919000, "318": 1756249101000, "319": 1756853182000, "321": 1756916783000, "322": 1756933104000, "323": 1756934600000, "324": 1756935087000, "326": 1757007157000}, "params": {"machine": ["gh-runner"], "python": ["3.10"], "Cython": [""], "build": [""], "packaging": [""], "branch": ["HEAD"]}, "graph_param_list": [{"machine": "gh-runner", "python": "3.10", "Cython": "", "build": "", "packaging": "", "branch": "HEAD"}], "benchmarks": {"benchmarks.time_database_connection_help": {"code": "def time_database_connection_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for database_connection\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"database_connection\", \"--help\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_database_connection_help", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "074d71554db1f54017ecc860ba5cde2e99fa2d1303d7a726dd672b55e6553c6d", "warmup_time": -1}, "benchmarks.time_download_help": {"code": "def time_download_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for download\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"download\", \"--help\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_download_help", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "50b3d711c54144a66a40aaf1fdb3fd2d57740df17bc1ee7f6bfbf04334ffbd33", "warmup_time": -1}, "benchmarks.time_help": {"code": "def time_help():\n    \"\"\"\n    time how long it takes to run --help from the CLI\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"--help\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_help", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "869a14d6a4b498042fb46c6100c1d810a36514446471b46798d86255fce3e355", "warmup_time": -1}, "benchmarks.time_import": {"code": "def time_import():\n    \"\"\"\n    time how long it takes to import our package. This should stay relatively fast.\n\n    Note, the actual import time will be slightly lower than this on a comparable system\n    However, high import times do affect this metric proportionally.\n    \"\"\"\n    result = subprocess.run([\"python\", \"-c\", \"import hyrax\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_import", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6a64ee071d3191fd146072ef269ea2f274ab7d7e90f8b4958584aa5636e6d64c", "warmup_time": -1}, "benchmarks.time_infer_help": {"code": "def time_infer_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for infer\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"infer\", \"--help\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_infer_help", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "3d49904114f6a63a32cf099bf9a4fb986de4285df6eddc0a5ea855effcf3fb25", "warmup_time": -1}, "benchmarks.time_lookup_help": {"code": "def time_lookup_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for lookup\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"lookup\", \"--help\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_lookup_help", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "12248d850368f773ddf88f0c779d8a1090f15b753675c3b607339ddd8d0d5e4a", "warmup_time": -1}, "benchmarks.time_nb_obj_construct": {"code": "def time_nb_obj_construct():\n    \"\"\"\n    time how long notebook users must wait for our interface object to construct\n    \"\"\"\n    hyrax.Hyrax()", "min_run_count": 2, "name": "benchmarks.time_nb_obj_construct", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "5fa120dae3cc7ce68885b5098a7d010151c4f44a4c46acba2b536e55775aa8b8", "warmup_time": -1}, "benchmarks.time_nb_obj_dir": {"code": "def time_nb_obj_dir():\n    \"\"\"\n    Time how long it takes to construct the interface object and load the\n    dynamcally generated list of verbs using `dir()`\n    \"\"\"\n    h = hyrax.Hyrax()\n    dir(h)", "min_run_count": 2, "name": "benchmarks.time_nb_obj_dir", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "f8b0daee1ef646aaea154b1ee9e661ce586b1b0073b2e26bd9fdf014c98c2f21", "warmup_time": -1}, "benchmarks.time_prepare_help": {"code": "def time_prepare_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for prepare\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"prepare\", \"--help\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_prepare_help", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "586a018de0f515b9d5576edf77a70be08d6e14757b282e8408cfdae3f2321d98", "warmup_time": -1}, "benchmarks.time_rebuild_manifest_help": {"code": "def time_rebuild_manifest_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for rebuild_manifest\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"rebuild_manifest\", \"--help\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_rebuild_manifest_help", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "75c72b4d902276b452aa080d05007fde289454004542bd926c0a1bac4190eb0d", "warmup_time": -1}, "benchmarks.time_save_to_database_help": {"code": "def time_save_to_database_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for save_to_database\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"save_to_database\", \"--help\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_save_to_database_help", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "a64a33bc999da1f4ae4d41b65038c9e29bb55b1fab9ec95f04c1b3b1d2c1f21d", "warmup_time": -1}, "benchmarks.time_train_help": {"code": "def time_train_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for train\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"train\", \"--help\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_train_help", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "6e3bccf7cc8666d49e9fd52838e601745f958f6fdefd66252020cf38ede4320c", "warmup_time": -1}, "benchmarks.time_umap_help": {"code": "def time_umap_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for umap\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"umap\", \"--help\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_umap_help", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "e76c6a5f58d7e66a935f286d9afecfff64edd2df937f33f74fbbc9a433f08e58", "warmup_time": -1}, "benchmarks.time_visualize_help": {"code": "def time_visualize_help():\n    \"\"\"\n    time how long it takes to do verb-specific help for visualize\n    \"\"\"\n    result = subprocess.run([\"hyrax\", \"visualize\", \"--help\"])\n    assert result.returncode == 0", "min_run_count": 2, "name": "benchmarks.time_visualize_help", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "c3ea3d131fe20f6e7d7b727c7b7f0b76b1502499687ec0b17a4924e50925f09b", "warmup_time": -1}, "data_request_benchmarks.DatasetRequestBenchmarks.time_request_all_data": {"code": "class DatasetRequestBenchmarks:\n    def time_request_all_data(self):\n        \"\"\"Benchmark the amount of time needed to retrieve all the data from\n        the random dataset\n        \"\"\"\n        for indx in self.indexes:\n            self.ds[indx]\n\n    def setup(self):\n        \"\"\"Prepare for benchmark by defining and setting up a random dataset\"\"\"\n        self.tmp_dir = tempfile.TemporaryDirectory()\n        self.input_dir = Path(self.tmp_dir.name)\n    \n        self.h = Hyrax()\n        self.h.config[\"general\"][\"results_dir\"] = str(self.input_dir)\n        self.h.config[\"data_set\"][\"name\"] = \"HyraxRandomDataset\"\n    \n        num_vectors = 4096\n        self.h.config[\"data_set.random_dataset\"][\"size\"] = num_vectors\n        self.h.config[\"data_set.random_dataset\"][\"seed\"] = 0\n        self.h.config[\"data_set.random_dataset\"][\"shape\"] = [3, 64, 64]\n    \n        self.ds = self.h.prepare()\n    \n        self.indexes = np.random.randint(0, num_vectors, size=128, dtype=int)", "min_run_count": 2, "name": "data_request_benchmarks.DatasetRequestBenchmarks.time_request_all_data", "number": 0, "param_names": [], "params": [], "repeat": 0, "rounds": 2, "sample_time": 0.01, "type": "time", "unit": "seconds", "version": "57b0481d597836d6f4a2e747e818f43e7f0616fb36264dc40b46772ac5e0c2c2", "warmup_time": -1}, "vector_db_benchmarks.VectorDBInsertBenchmarks.peakmem_load_vector_db": {"code": "class VectorDBInsertBenchmarks:\n    def peakmem_load_vector_db(self, vector_length, vector_db_implementation):\n        \"\"\"Memory benchmark for loading a vector database.\"\"\"\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            self.h.save_to_database(output_dir=Path(tmp_dir))\n\n    def setup(self, vector_length, vector_db_implementation):\n        \"\"\"Set up for vector database benchmarks. Create a temporary directory,\n        configure Hyrax with a loopback model, and generate a random dataset, run\n        inference to create the result files for insertion into the vector database.\"\"\"\n        self.tmp_dir = tempfile.TemporaryDirectory()\n        self.input_dir = Path(self.tmp_dir.name)\n    \n        self.h = Hyrax()\n        self.h.config[\"general\"][\"results_dir\"] = str(self.input_dir)\n        self.h.config[\"data_set\"][\"name\"] = \"HyraxRandomDataset\"\n        self.h.config[\"model\"][\"name\"] = \"HyraxLoopback\"\n    \n        # Default inference batch size is 512, so this should result in 4 batch files\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"size\"] = 2048\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"seed\"] = 0\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"shape\"] = [vector_length]\n    \n        # Qdrant requires the vector size in order to create its collections\n        self.h.config[\"vector_db\"][\"qdrant\"][\"vector_size\"] = vector_length\n    \n        weights_file = self.input_dir / \"fakeweights\"\n        with open(weights_file, \"a\"):\n            pass\n        self.h.config[\"infer\"][\"model_weights_file\"] = str(weights_file)\n    \n        self.h.config[\"vector_db\"][\"name\"] = vector_db_implementation\n    \n        self.h.infer()", "name": "vector_db_benchmarks.VectorDBInsertBenchmarks.peakmem_load_vector_db", "param_names": ["vector_length", "vector_db_implementation"], "params": [["64", "256", "2048", "16384"], ["'chromadb'", "'qdrant'"]], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "24eaa2326802b341c86786faeaa0da3ec5e3f0db9b7e7295edecf22c94f7c6fe"}, "vector_db_benchmarks.VectorDBInsertBenchmarks.time_load_vector_db": {"code": "class VectorDBInsertBenchmarks:\n    def time_load_vector_db(self, vector_length, vector_db_implementation):\n        \"\"\"Timing benchmark for loading a vector database.\"\"\"\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            self.h.save_to_database(output_dir=Path(tmp_dir))\n\n    def setup(self, vector_length, vector_db_implementation):\n        \"\"\"Set up for vector database benchmarks. Create a temporary directory,\n        configure Hyrax with a loopback model, and generate a random dataset, run\n        inference to create the result files for insertion into the vector database.\"\"\"\n        self.tmp_dir = tempfile.TemporaryDirectory()\n        self.input_dir = Path(self.tmp_dir.name)\n    \n        self.h = Hyrax()\n        self.h.config[\"general\"][\"results_dir\"] = str(self.input_dir)\n        self.h.config[\"data_set\"][\"name\"] = \"HyraxRandomDataset\"\n        self.h.config[\"model\"][\"name\"] = \"HyraxLoopback\"\n    \n        # Default inference batch size is 512, so this should result in 4 batch files\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"size\"] = 2048\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"seed\"] = 0\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"shape\"] = [vector_length]\n    \n        # Qdrant requires the vector size in order to create its collections\n        self.h.config[\"vector_db\"][\"qdrant\"][\"vector_size\"] = vector_length\n    \n        weights_file = self.input_dir / \"fakeweights\"\n        with open(weights_file, \"a\"):\n            pass\n        self.h.config[\"infer\"][\"model_weights_file\"] = str(weights_file)\n    \n        self.h.config[\"vector_db\"][\"name\"] = vector_db_implementation\n    \n        self.h.infer()", "min_run_count": 2, "name": "vector_db_benchmarks.VectorDBInsertBenchmarks.time_load_vector_db", "number": 0, "param_names": ["vector_length", "vector_db_implementation"], "params": [["64", "256", "2048", "16384"], ["'chromadb'", "'qdrant'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "d383cfd21c7365ebec9a6c224f9f524c3f9a137fae9b8f5ebb710ceb881bc0cd", "warmup_time": -1}, "vector_db_benchmarks.VectorDBSearchBenchmarks.peakmem_search_by_vector_many_shards": {"code": "class VectorDBSearchBenchmarks:\n    def peakmem_search_by_vector_many_shards(self, shard_size_limit, vector_db_implementation):\n        \"\"\"Benchmark memory to perform a search by ID on a dataset with many shards.\"\"\"\n        self.db.search_by_vector(self.data_sample, k=1)\n\n    def setup(self, shard_size_limit, vector_db_implementation):\n        \"\"\"Set up for vector database benchmarks. Create a temporary directory,\n        configure Hyrax with a loopback model, and generate a random dataset, run\n        inference to create the result files for insertion into the vector database.\"\"\"\n        self.tmp_input_dir = tempfile.TemporaryDirectory()\n        self.tmp_output_dir = tempfile.TemporaryDirectory()\n        self.input_dir = Path(self.tmp_input_dir.name)\n        self.output_dir = Path(self.tmp_output_dir.name)\n    \n        self.vector_length = 1024\n    \n        self.h = Hyrax()\n        self.h.config[\"general\"][\"results_dir\"] = str(self.input_dir)\n        self.h.config[\"data_set\"][\"name\"] = \"HyraxRandomDataset\"\n        self.h.config[\"data_loader\"][\"batch_size\"] = 4096\n        self.h.config[\"model\"][\"name\"] = \"HyraxLoopback\"\n    \n        # Default inference batch size is 512, so this should result in 4 batch files\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"size\"] = 4096\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"seed\"] = 0\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"shape\"] = [1024]\n    \n        # Create a fake weights file and then run inference on the random dataset\n        weights_file = self.input_dir / \"fakeweights\"\n        with open(weights_file, \"a\"):\n            pass\n        self.h.config[\"infer\"][\"model_weights_file\"] = str(weights_file)\n    \n        self.h.infer()\n    \n        # Get the list of dataset ids\n        self.ds = self.h.prepare()\n        self.data_sample = self.ds[4001][\"image\"].numpy()\n    \n        self.h.config[\"vector_db\"][\"name\"] = vector_db_implementation\n        self.h.config[\"vector_db\"][\"chromadb\"][\"shard_size_limit\"] = shard_size_limit\n        # Qdrant requires the vector size in order to create its collections\n        self.h.config[\"vector_db\"][\"qdrant\"][\"vector_size\"] = 4096\n    \n        # Save inference results to vector database and create a db connection\n        self.h.save_to_database(output_dir=Path(self.output_dir))\n        self.db = self.h.database_connection(self.output_dir)", "name": "vector_db_benchmarks.VectorDBSearchBenchmarks.peakmem_search_by_vector_many_shards", "param_names": ["shard_size_limit", "vector_db_implementation"], "params": [["64", "128"], ["'chromadb'", "'qdrant'"]], "timeout": 120, "type": "peakmemory", "unit": "bytes", "version": "9b794d38f02ccb022b00ede25483ee97ccc955026345d72627b7083854cca3f8"}, "vector_db_benchmarks.VectorDBSearchBenchmarks.time_search_by_vector_many_shards": {"code": "class VectorDBSearchBenchmarks:\n    def time_search_by_vector_many_shards(self, shard_size_limit, vector_db_implementation):\n        \"\"\"Benchmark timing to perform a search by ID on a dataset with many shards.\"\"\"\n        self.db.search_by_vector(self.data_sample, k=1)\n\n    def setup(self, shard_size_limit, vector_db_implementation):\n        \"\"\"Set up for vector database benchmarks. Create a temporary directory,\n        configure Hyrax with a loopback model, and generate a random dataset, run\n        inference to create the result files for insertion into the vector database.\"\"\"\n        self.tmp_input_dir = tempfile.TemporaryDirectory()\n        self.tmp_output_dir = tempfile.TemporaryDirectory()\n        self.input_dir = Path(self.tmp_input_dir.name)\n        self.output_dir = Path(self.tmp_output_dir.name)\n    \n        self.vector_length = 1024\n    \n        self.h = Hyrax()\n        self.h.config[\"general\"][\"results_dir\"] = str(self.input_dir)\n        self.h.config[\"data_set\"][\"name\"] = \"HyraxRandomDataset\"\n        self.h.config[\"data_loader\"][\"batch_size\"] = 4096\n        self.h.config[\"model\"][\"name\"] = \"HyraxLoopback\"\n    \n        # Default inference batch size is 512, so this should result in 4 batch files\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"size\"] = 4096\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"seed\"] = 0\n        self.h.config[\"data_set\"][\"HyraxRandomDataset\"][\"shape\"] = [1024]\n    \n        # Create a fake weights file and then run inference on the random dataset\n        weights_file = self.input_dir / \"fakeweights\"\n        with open(weights_file, \"a\"):\n            pass\n        self.h.config[\"infer\"][\"model_weights_file\"] = str(weights_file)\n    \n        self.h.infer()\n    \n        # Get the list of dataset ids\n        self.ds = self.h.prepare()\n        self.data_sample = self.ds[4001][\"image\"].numpy()\n    \n        self.h.config[\"vector_db\"][\"name\"] = vector_db_implementation\n        self.h.config[\"vector_db\"][\"chromadb\"][\"shard_size_limit\"] = shard_size_limit\n        # Qdrant requires the vector size in order to create its collections\n        self.h.config[\"vector_db\"][\"qdrant\"][\"vector_size\"] = 4096\n    \n        # Save inference results to vector database and create a db connection\n        self.h.save_to_database(output_dir=Path(self.output_dir))\n        self.db = self.h.database_connection(self.output_dir)", "min_run_count": 2, "name": "vector_db_benchmarks.VectorDBSearchBenchmarks.time_search_by_vector_many_shards", "number": 0, "param_names": ["shard_size_limit", "vector_db_implementation"], "params": [["64", "128"], ["'chromadb'", "'qdrant'"]], "repeat": 0, "rounds": 2, "sample_time": 0.01, "timeout": 120, "type": "time", "unit": "seconds", "version": "75747b093061afac7a739ae945131dbbfbf53ce41f2e5b5cf5bd7720fc50d45f", "warmup_time": -1}}, "machines": {"gh-runner": {"machine": "gh-runner", "version": 1}}, "tags": {"v0.1": 67, "v0.1.1": 70, "v0.1.2": 74, "v0.2": 153, "v0.3": 187, "v0.3.1": 189, "v0.3.2": 248, "v0.4.0": 281, "v0.5.0": 315, "v1.0rc": 180}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}