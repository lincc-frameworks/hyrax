{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Hyrax Custom Dataset Classes\n",
    "\n",
    "In this notebook we are going to build up a custom dataset class for hyrax, and show how you can use the \n",
    "`prepare` verb in hyrax to test various aspects of your new dataclass.\n",
    "\n",
    "First we will create some synthetic data. We'll create 1000 10x10 numpy arrays with associated random file names.\n",
    "Nothing in this cell is specific to developing a Hyrax dataset, it's just setting things up in a semi-realistic way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "num_tensors = 1000\n",
    "\n",
    "# Generate filenames\n",
    "alphabet = list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "filename_length = 15\n",
    "filenames = [\"\".join(list(rng.choice(alphabet, 15))) for _ in range(num_tensors)]\n",
    "\n",
    "# Generate numpy arrays\n",
    "shape = (3, 10, 10)\n",
    "random_data = {file: rng.random(size=shape, dtype=np.float32) for file in filenames}\n",
    "\n",
    "\n",
    "def _read_tensor(filename: str):\n",
    "    return random_data[filename]\n",
    "\n",
    "\n",
    "def _list_filenames(data_location):\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a custom Dataset class\n",
    "\n",
    "We will treat these tensors as if they are on the filesystem, and write a dataclass that gives hyrax access to \n",
    "these \"files.\"\n",
    "\n",
    "Two utility funcitons are defined above for demonstration purposes. `_read_tensor` returns a numpy array from our \"files\", \n",
    "and `_list_filenames` lists the filenames in our \"directory\".\n",
    "\n",
    "The first thing we need to do is make a new class derived from HyraxDataset and torch.Dataset as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from hyrax.data_sets import HyraxDataset\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class MyDataset(HyraxDataset, Dataset):\n",
    "    def __init__(self, config: dict, data_location: Union[Path, str] = None):\n",
    "        # List the filenames\n",
    "        self.filenames = _list_filenames(data_location)\n",
    "\n",
    "        # Call our super-class constructor (handles many things)\n",
    "        super().__init__(config)\n",
    "\n",
    "    def get_object_id(self, index: int):\n",
    "        \"\"\"Return the object_id of a particular object\"\"\"\n",
    "        return self.filenames[index]\n",
    "\n",
    "    def get_image(self, index: int):\n",
    "        \"\"\"Read the image from disk\"\"\"\n",
    "        filename = self.filenames[index]\n",
    "        return _read_tensor(filename)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key aspects of this class that you will need to replicate are:\n",
    "\n",
    "* `__init__` must call `super().__init__(config)` This is important for hyrax to function appropriately, and \n",
    "gives you access to hyrax's config in other functions should you want it later.\n",
    "\n",
    "* `get_object_id` and `get_image` You must implement a function like this for each column in your data that\n",
    "you want to make available to machine learning each take an index into your dataset and should return the\n",
    "relevant piece of data. `get_object_id` or a coulumn of similar unique identifiers is required.\n",
    "\n",
    "* `__len__` must return the length of your dataset.\n",
    "\n",
    "Note that all of these are instance methods that use `self` as the first argument. This `self` is the current\n",
    "`MyDataset` object, and allows you to set and get values as is done with `self.filenames` in the code above.\n",
    "\n",
    "The functions `_list_filenames()` and `_read_tensor()` are both reading our fake data, and are there so we \n",
    "have an effective demonstration. The functional organization of your analogous file reading code is entirely \n",
    "up to you!\n",
    "\n",
    "\n",
    "We're now going to start up Hyrax and use the `prepare` verb to create an instance of this class and see\n",
    "that it works correctly. Note how we have set up `config[\"data_request\"]` to specify the name of our primary \n",
    "object id, the data location, and the dataset class name. This is how hyrax knows to invoke our class. The \n",
    "outermost dictionary level where we use `\"train\"` as a key specifies the stage of hyrax that will use this\n",
    "dataset. To use this across multiple steps (e.g. `\"train\"`, `\"verify\"`, `\"test\"`, `\"infer\"`) you simply add \n",
    "another key to the top level dictionary and copy the `\"data\"` part.\n",
    "\n",
    "Our `h.prepare()` line in the script will have the effect of calling our `__init__` function with the \n",
    "current hyrax config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-17 16:14:38,480 hyrax.prepare:INFO] Finished Prepare\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dict = {'train': Name: data (primary dataset)\n",
      "  Dataset class: MyDataset\n",
      "  Data location: /fake/path/to/some/data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: image, object_id\n",
      "}\n",
      "type(data_provider) = <class 'hyrax.data_sets.data_provider.DataProvider'>\n",
      "data_provider.prepped_datasets = {'data': <__main__.MyDataset object at 0x39a4d3c10>}\n",
      "type(dataset) = <class '__main__.MyDataset'>\n"
     ]
    }
   ],
   "source": [
    "import hyrax\n",
    "\n",
    "h = hyrax.Hyrax()\n",
    "h.config[\"data_request\"] = {\n",
    "    \"train\": {\n",
    "        \"data\": {\n",
    "            \"dataset_class\": \"MyDataset\",\n",
    "            \"primary_id_field\": \"object_id\",\n",
    "            \"data_location\": \"/fake/path/to/some/data\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "dataprovider_dict = h.prepare()\n",
    "\n",
    "print(f\"dataset_dict = {dataprovider_dict}\")\n",
    "data_provider = dataprovider_dict[\"train\"]\n",
    "print(f\"type(data_provider) = {type(data_provider)}\")\n",
    "\n",
    "print(f\"data_provider.prepped_datasets = {data_provider.prepped_datasets}\")\n",
    "dataset = data_provider.prepped_datasets[\"data\"]\n",
    "print(f\"type(dataset) = {type(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `dataset_dict` we get back has the same structure as our data request, so we must extract the\n",
    "`\"train\"` member. When we do that, we don't quite get a dataset. \n",
    "\n",
    "We get a `DataProvider` which is a wrapper around multiple datasets, allowing for multimodal data access.\n",
    "\n",
    "If we want to find our actul class, we have to look at the `prepped_dataset` member under the same key \n",
    "we used in our data request `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Now that we have a copy of our dataset, and the data provider we can now test out our functions.\n",
    "\n",
    "On our object, we can check that `get_object_id` and `get_image` return what we expect. We're also going to \n",
    "call `len()` on the dataset which will have the effect of calling our `__len__` function.\n",
    "\n",
    "Since we configured hyrax to use our `object_id` column as the primary ID, we can also see our IDs returned\n",
    "from `DataProvider`'s `.ids()` method.\n",
    "\n",
    "We can finally do indexed `[]` access on the `DataProvider` to see that we get a dictionary with all of our \n",
    "fields represented. Hyrax automatically detects the functions added to a dataset class when the names are\n",
    "of the pattern `get_<field name>`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.get_object_id(0) = DLWPOJfSttYujNJ\n",
      "dataset.get_image(0).shape = (3, 10, 10)\n",
      "type(dataset.get_image(0)) = <class 'numpy.ndarray'>\n",
      "len(dataset) = 1000\n",
      "len(data_provider) = 1000\n",
      "data_provider.ids()[:5] = ['DLWPOJfSttYujNJ', 'NwHxIIyjgEWzSbb', 'botahsGeHaadJyt', 'HEkxzqgFQzLEDDb', 'lNVmUbKlxIjsrUT']\n",
      "data_provider[0] = \n",
      "{'data': {'image': 'np.ndarray(shape=(3, 10, 10), dtype=float32)', 'object_id': 'DLWPOJfSttYujNJ'}, 'object_id': 'DLWPOJfSttYujNJ'}\n"
     ]
    }
   ],
   "source": [
    "def summarize_numpy(obj):\n",
    "    \"\"\"Printing helper to summaryize numpy arrays\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return f\"np.ndarray(shape={obj.shape}, dtype={obj.dtype})\"\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: summarize_numpy(v) for k, v in obj.items()}\n",
    "    return obj\n",
    "\n",
    "\n",
    "object_id_zero = dataset.get_object_id(0)\n",
    "print(f\"dataset.get_object_id(0) = {object_id_zero}\")\n",
    "\n",
    "image_zero = dataset.get_image(0)\n",
    "print(f\"dataset.get_image(0).shape = {image_zero.shape}\")\n",
    "print(f\"type(dataset.get_image(0)) = {type(image_zero)}\")\n",
    "\n",
    "print(f\"len(dataset) = {len(dataset)}\")\n",
    "print(f\"len(data_provider) = {len(data_provider)}\")\n",
    "\n",
    "print(f\"data_provider.ids()[:5] = {data_provider.ids()[:5]}\")\n",
    "\n",
    "item = data_provider[0]\n",
    "print(\"data_provider[0] = \", end=\"\\n\")\n",
    "print(summarize_numpy(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset class is suitable for training or inference with Hyrax; however, you may want to read on to learn\n",
    "about more advanced features such as metadata, and configuration access.\n",
    "\n",
    "Below is a short example that uses the HyraxAutoencoder built-in model, demonstrating that training is possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-17 16:14:38,733 hyrax.models.model_registry:INFO] Setting model's self.optimizer from config: torch.optim.SGD with arguments: {'lr': 0.01, 'momentum': 0.9}.\n",
      "[2026-02-17 16:14:38,734 hyrax.models.model_registry:INFO] Setting model's self.criterion from config: torch.nn.CrossEntropyLoss with default arguments.\n",
      "[2026-02-17 16:14:38,734 hyrax.models.model_registry:INFO] Setting model's self.scheduler from config: torch.optim.lr_scheduler.ExponentialLR\n",
      "with arguments: {'gamma': 1}.\n",
      "[2026-02-17 16:14:38,734 hyrax.verbs.train:INFO] \u001b[1m\u001b[30m\u001b[42mTraining model:\u001b[0m HyraxAutoencoder\n",
      "[2026-02-17 16:14:38,734 hyrax.verbs.train:INFO] \u001b[1m\u001b[30m\u001b[42mTraining dataset(s):\u001b[0m\n",
      "{'train': Name: data (primary dataset)\n",
      "  Dataset class: MyDataset\n",
      "  Data location: /fake/path/to/some/data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: image, object_id\n",
      "}\n",
      "2026-02-17 16:14:38,736 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Name: data (primary': \n",
      "\t{'sampler': <hyrax.pytorch_ignite.SubsetSequentialSampler object at 0x398738650>, 'batch_size': 512, 'shuffle': False, 'collate_fn': <bound method DataProvider.collate of Name: data (primary dataset)\n",
      "  Dataset class: MyDataset\n",
      "  Data location: /fake/path/to/some/data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: image, object_id\n",
      ">, 'pin_memory': False}\n",
      "2026-02-17 16:14:38,736 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Name: data (primary': \n",
      "\t{'sampler': <hyrax.pytorch_ignite.SubsetSequentialSampler object at 0x10557aed0>, 'batch_size': 512, 'shuffle': False, 'collate_fn': <bound method DataProvider.collate of Name: data (primary dataset)\n",
      "  Dataset class: MyDataset\n",
      "  Data location: /fake/path/to/some/data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: image, object_id\n",
      ">, 'pin_memory': False}\n",
      "/Users/mtauraso/miniforge3/envs/hyrax311/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2026/02/17 16:14:38 INFO mlflow.tracking.fluent: Experiment with name 'notebook' does not exist. Creating a new experiment.\n",
      "2026/02/17 16:14:38 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/02/17 16:14:38 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4709a7df6e94c3aa1129babc2e6b87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fcc510d62146e8a3beae3065a97123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52606458db44783b387896e6cf35a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f6a5d197d44d78af3c10c0b60885b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678972910feb4322a021c7e61e2f2c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a1e4ee746443ac8f598a5571c367ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa43189fe1e48adbd8253848cc621d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4805aec1844c5c8f98cdddbb464d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca9a7b68aea45aa82bdd2eec4260dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9011a586444469afbd67a3dcc229d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-17 16:14:39,721 hyrax.pytorch_ignite:INFO] Total training time: 0.96[s]\n",
      "2026/02/17 16:14:39 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2026/02/17 16:14:39 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[2026-02-17 16:14:39,731 hyrax.verbs.train:INFO] Finished Training\n"
     ]
    }
   ],
   "source": [
    "import hyrax\n",
    "\n",
    "h = hyrax.Hyrax()\n",
    "h.config[\"model\"][\"name\"] = \"HyraxAutoencoder\"\n",
    "h.config[\"data_request\"] = {\n",
    "    \"train\": {\n",
    "        \"data\": {\n",
    "            \"dataset_class\": \"MyDataset\",\n",
    "            \"primary_id_field\": \"object_id\",\n",
    "            \"data_location\": \"/fake/path/to/some/data\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "model = h.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending to support visualization\n",
    "\n",
    "This section is primarily concerned with binding different sorts of metadata to your dataset. This metadata\n",
    "is surfaced by the Hyrax visualization components allowing you to link your latent space representation\n",
    "back to astronomical parameters of your original dataset that are not involved in inference.\n",
    "\n",
    "When we built `MyDataclass` above, used a simple way to initialize the `HyraxDataset` superclass; however,\n",
    "we can get more from it. Any class that inherits from `HyraxDataset` can provide an astropy `Table` of values \n",
    "in the same order that the `get_<column name>` functions use. This allows each tensor in the dataset to have \n",
    "associated scalar data such as ra/dec, ephemeris parameters, redshift, magnitude, etc. For our class there \n",
    "currently is no metadata.\n",
    "\n",
    "We are now going to generate some fake metadata and then add it into the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "\n",
    "ras = rng.uniform(low=0.0, high=360.0, size=num_tensors) * u.deg\n",
    "decs = rng.uniform(low=-90.0, high=90.0, size=num_tensors) * u.deg\n",
    "\n",
    "\n",
    "def _read_metadata(path_to_data):\n",
    "    \"\"\"This is a pretend implementation so we don't use the path passed, which you might use\n",
    "    to find your .csv/.fits/.tsv catalog file and call astropy's Table.read().\n",
    "\n",
    "    We simply construct a table from our mock data\"\"\"\n",
    "    from astropy.table import Table\n",
    "\n",
    "    global ras, decs, filenames\n",
    "    return Table({\"object_id\": filenames, \"ra\": ras, \"dec\": decs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to override metadata we will provide `HyraxDataset` with an astropy table containing all of the metadata in the constructor for our class as shown below. We do this in `__init__` by passing an astropy table of our metadata to `super().__init__` as a second, optional argument.\n",
    "\n",
    "Note the new function `_read_metadata()` which constructs this table. On a real dataset this function would\n",
    "most likely call astropy's `Table.read` [high level interface](https://docs.astropy.org/en/latest/io/unified.html) to construct a table directly from your catalog.\n",
    "\n",
    "Note that we have re-implemented the entire class below so you can see all the parts working together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from hyrax.data_sets import HyraxDataset\n",
    "\n",
    "\n",
    "class MyDataset(HyraxDataset, Dataset):\n",
    "    def __init__(self, config: dict, data_location: Union[Path, str] = None):\n",
    "        # List the filenames\n",
    "        self.filenames = _list_filenames(data_location)\n",
    "\n",
    "        # Call our super-class constructor\n",
    "        metadata_table = _read_metadata(data_location)\n",
    "        super().__init__(config, metadata_table=metadata_table)\n",
    "\n",
    "    # Unchanged from before below this comment\n",
    "    def get_object_id(self, index: int):\n",
    "        \"\"\"Return the object_id of a particular object\"\"\"\n",
    "        return self.filenames[index]\n",
    "\n",
    "    def get_image(self, index: int):\n",
    "        \"\"\"Read the image from disk\"\"\"\n",
    "        filename = self.filenames[index]\n",
    "        return _read_tensor(filename)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our dataset class is passing up a metadata table, you can see that the `ra` and `dec` columns\n",
    "are now represented when we ask for data from the `DataProvider`.\n",
    "\n",
    "\n",
    "Under the hood, the datset has recieved a `metadata_fields` and `metadata` function which give hyrax internal \n",
    "tabular access to these fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-17 16:14:39,826 hyrax.prepare:INFO] Finished Prepare\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_provider[0] = \n",
      "{'data': {'dec': np.float64(-62.176968664821786),\n",
      "          'image': 'np.ndarray(shape=(3, 10, 10), dtype=float32)',\n",
      "          'object_id': 'DLWPOJfSttYujNJ',\n",
      "          'ra': np.float64(41.83089042356666)},\n",
      " 'object_id': 'DLWPOJfSttYujNJ'}\n",
      "\n",
      "Public attributes on data provider and their types:\n",
      "{'config': <class 'tomlkit.toml_document.TOMLDocument'>,\n",
      " 'filenames': <class 'list'>,\n",
      " 'get_dec': <class 'method'>,\n",
      " 'get_image': <class 'method'>,\n",
      " 'get_object_id': <class 'method'>,\n",
      " 'get_ra': <class 'method'>,\n",
      " 'is_iterable': <class 'method'>,\n",
      " 'is_map': <class 'method'>,\n",
      " 'metadata': <class 'method'>,\n",
      " 'metadata_fields': <class 'method'>,\n",
      " 'sample_data': <class 'method'>}\n"
     ]
    }
   ],
   "source": [
    "import hyrax\n",
    "from pprint import pprint\n",
    "\n",
    "h = hyrax.Hyrax()\n",
    "h.config[\"data_request\"] = {\n",
    "    \"train\": {\n",
    "        \"data\": {\n",
    "            \"dataset_class\": \"MyDataset\",\n",
    "            \"primary_id_field\": \"object_id\",\n",
    "            \"data_location\": \"/fake/path/to/some/data\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "dataprovider_dict = h.prepare()\n",
    "data_provider = dataprovider_dict[\"train\"]\n",
    "\n",
    "print(\"data_provider[0] = \")\n",
    "pprint(summarize_numpy(data_provider[0]))\n",
    "print(\"\")\n",
    "\n",
    "dataset = data_provider.prepped_datasets[\"data\"]\n",
    "print(\"Public attributes on data provider and their types:\")\n",
    "pprint({f: type(getattr(dataset, f)) for f in dir(dataset) if f[0] != \"_\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a Dataset capable of 'ra' and 'dec' metadata, we can do a full analysis with hyrax, `train`ing the model, `infer`ing the latent space, `umap`ping the latent space to a 2d representation, and `visualize`-ing the result.\n",
    "\n",
    "Note that we are configuring the visualizer to accept the `ra` and `dec` fields. We post-pend `data` because that is the name we've given our dataset in our data request. If multiple data sources supply an `ra` column, the ending part disambiguates which `ra` column is meant. We do not have multiple data sources here, because each of the `train` and `infer` dictionaries only has a single key: `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-17 16:14:39,904 hyrax.models.model_registry:INFO] Setting model's self.optimizer from config: torch.optim.SGD with arguments: {'lr': 0.01, 'momentum': 0.9}.\n",
      "[2026-02-17 16:14:39,905 hyrax.models.model_registry:INFO] Setting model's self.criterion from config: torch.nn.CrossEntropyLoss with default arguments.\n",
      "[2026-02-17 16:14:39,905 hyrax.models.model_registry:INFO] Setting model's self.scheduler from config: torch.optim.lr_scheduler.ExponentialLR\n",
      "with arguments: {'gamma': 1}.\n",
      "[2026-02-17 16:14:39,905 hyrax.verbs.train:INFO] \u001b[1m\u001b[30m\u001b[42mTraining model:\u001b[0m HyraxAutoencoder\n",
      "[2026-02-17 16:14:39,906 hyrax.verbs.train:INFO] \u001b[1m\u001b[30m\u001b[42mTraining dataset(s):\u001b[0m\n",
      "{'train': Name: data (primary dataset)\n",
      "  Dataset class: MyDataset\n",
      "  Data location: /fake/path/to/some/data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: dec, image, object_id, ra\n",
      ", 'infer': Name: data (primary dataset)\n",
      "  Dataset class: MyDataset\n",
      "  Data location: /fake/path/to/some/data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: dec, image, object_id, ra\n",
      "}\n",
      "2026-02-17 16:14:39,907 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Name: data (primary': \n",
      "\t{'sampler': <hyrax.pytorch_ignite.SubsetSequentialSampler object at 0x399976dd0>, 'batch_size': 512, 'shuffle': False, 'collate_fn': <bound method DataProvider.collate of Name: data (primary dataset)\n",
      "  Dataset class: MyDataset\n",
      "  Data location: /fake/path/to/some/data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: dec, image, object_id, ra\n",
      ">, 'pin_memory': False}\n",
      "2026-02-17 16:14:39,907 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Name: data (primary': \n",
      "\t{'sampler': <hyrax.pytorch_ignite.SubsetSequentialSampler object at 0x129bd9c90>, 'batch_size': 512, 'shuffle': False, 'collate_fn': <bound method DataProvider.collate of Name: data (primary dataset)\n",
      "  Dataset class: MyDataset\n",
      "  Data location: /fake/path/to/some/data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: dec, image, object_id, ra\n",
      ">, 'pin_memory': False}\n",
      "/Users/mtauraso/miniforge3/envs/hyrax311/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2026/02/17 16:14:39 INFO mlflow.tracking.fluent: Experiment with name 'notebook' does not exist. Creating a new experiment.\n",
      "2026/02/17 16:14:39 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/02/17 16:14:39 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94c8fabb68f4daab8cabfb7a228e1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d617a1c23e46ff87cd5b110ebe5345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da8eba84c4c4a66a6832d1ada606d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acd0106ce66461d84d50eaf625a3350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bc8a9ea4ba4adfa5b7a54e8c607816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be456becea6c43e2bc611b2e881db22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0771c7348adc4b0f939145546491a435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e8f1bacc174abd8e30012073e6d743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe958348089b4a09ae14f5bc37950eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c724cb71bf43a8b068ac4047a4fbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-17 16:14:40,908 hyrax.pytorch_ignite:INFO] Total training time: 0.97[s]\n",
      "2026/02/17 16:14:40 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2026/02/17 16:14:40 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[2026-02-17 16:14:40,921 hyrax.verbs.train:INFO] Finished Training\n",
      "[2026-02-17 16:14:40,972 hyrax.models.model_registry:INFO] Setting model's self.optimizer from config: torch.optim.SGD with arguments: {'lr': 0.01, 'momentum': 0.9}.\n",
      "[2026-02-17 16:14:40,973 hyrax.models.model_registry:INFO] Setting model's self.criterion from config: torch.nn.CrossEntropyLoss with default arguments.\n",
      "[2026-02-17 16:14:40,973 hyrax.models.model_registry:INFO] Setting model's self.scheduler from config: torch.optim.lr_scheduler.ExponentialLR\n",
      "with arguments: {'gamma': 1}.\n",
      "[2026-02-17 16:14:40,973 hyrax.verbs.infer:INFO] \u001b[1m\u001b[30m\u001b[42mInference model:\u001b[0m HyraxAutoencoder\n",
      "[2026-02-17 16:14:40,973 hyrax.verbs.infer:INFO] \u001b[1m\u001b[30m\u001b[42mInference dataset(s):\u001b[0m\n",
      "{'train': Name: data (primary dataset)\n",
      "  Dataset class: MyDataset\n",
      "  Data location: /fake/path/to/some/data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: dec, image, object_id, ra\n",
      ", 'infer': Name: data (primary dataset)\n",
      "  Dataset class: MyDataset\n",
      "  Data location: /fake/path/to/some/data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: dec, image, object_id, ra\n",
      "}\n",
      "2026-02-17 16:14:40,974 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Name: data (primary': \n",
      "\t{'sampler': None, 'batch_size': 512, 'shuffle': False, 'collate_fn': <bound method DataProvider.collate of Name: data (primary dataset)\n",
      "  Dataset class: MyDataset\n",
      "  Data location: /fake/path/to/some/data\n",
      "  Primary ID field: object_id\n",
      "  Requested fields: dec, image, object_id, ra\n",
      ">, 'pin_memory': False}\n",
      "[2026-02-17 16:14:40,987 hyrax.models.model_utils:INFO] Updated config['infer']['model_weights_file'] to: /Users/mtauraso/src/hyrax/docs/pre_executed/results/20260217-161439-train-vc18/example_model.pth\n",
      "[2026-02-17 16:14:40,989 hyrax.verbs.infer:INFO] Saving inference results at: /Users/mtauraso/src/hyrax/docs/pre_executed/results/20260217-161440-infer-tni7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a8ce8e3a7c4dd6a72ff92caecf903d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-17 16:14:41,169 hyrax.pytorch_ignite:INFO] Total evaluation time: 0.13[s]\n",
      "[2026-02-17 16:14:41,206 hyrax.verbs.infer:INFO] Inference Complete.\n",
      "[2026-02-17 16:14:41,594 hyrax.verbs.umap:INFO] Saving UMAP results to /Users/mtauraso/src/hyrax/docs/pre_executed/results/20260217-161441-umap-Whiu\n",
      "[2026-02-17 16:14:41,649 hyrax.verbs.umap:INFO] Fitting the UMAP\n",
      "[2026-02-17 16:14:42,389 hyrax.verbs.umap:INFO] Saving fitted UMAP Reducer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ddb03969674504817aa99f93877eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating lower dimensional representation using UMAP::   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-17 16:14:43,761 hyrax.verbs.umap:INFO] Finished transforming all data through UMAP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hyrax.data_sets.inference_dataset.InferenceDataSet at 0x399771d10>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyrax\n",
    "\n",
    "h = hyrax.Hyrax()\n",
    "h.config[\"data_request\"] = {\n",
    "    \"train\": {\n",
    "        \"data\": {\n",
    "            \"dataset_class\": \"MyDataset\",\n",
    "            \"primary_id_field\": \"object_id\",\n",
    "            \"data_location\": \"/fake/path/to/some/data\",\n",
    "        }\n",
    "    },\n",
    "    \"infer\": {\n",
    "        \"data\": {\n",
    "            \"dataset_class\": \"MyDataset\",\n",
    "            \"primary_id_field\": \"object_id\",\n",
    "            \"data_location\": \"/fake/path/to/some/data\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "h.config[\"visualize\"][\"fields\"] = [\"ra_data\", \"dec_data\"]\n",
    "h.config[\"model\"][\"name\"] = \"HyraxAutoencoder\"\n",
    "\n",
    "h.train()\n",
    "h.infer()\n",
    "h.umap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-02-17 16:14:43,878 hyrax.verbs.visualize:INFO] UMAP directory not specified at runtime. Reading from config values.\n",
      "[2026-02-17 16:14:43,985 hyrax.verbs.visualize:INFO] Rendering UMAP from the following directory: /Users/mtauraso/src/hyrax/docs/pre_executed/results/20260217-161441-umap-Whiu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const version = '3.8.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n  const BK_RE = /^https:\\/\\/cdn\\.bokeh\\.org\\/bokeh\\/(release|dev)\\/bokeh-/;\n  const PN_RE = /^https:\\/\\/cdn\\.holoviz\\.org\\/panel\\/[^/]+\\/dist\\/panel/i;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, Bokeh, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      const shouldSkip = skip.includes(escaped) || existing_scripts.includes(escaped)\n      const isBokehOrPanel = BK_RE.test(escaped) || PN_RE.test(escaped)\n      const missingOrBroken = Bokeh == null || Bokeh.Panel == null || (Bokeh.version != version && !Bokeh.versions?.has(version)) || Bokeh.versions?.get(version)?.Panel == null;\n      if (shouldSkip && !(isBokehOrPanel && missingOrBroken)) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.6/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.2.min.js\", \"https://cdn.holoviz.org/panel/1.8.6/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false;\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true;\n      root._bokeh_onload_callbacks = [];\n      const bokeh_loaded = Bokeh != null && ((Bokeh.version === version && Bokeh.Panel) || (Bokeh.versions?.has(version) && Bokeh.versions.get(version)?.Panel));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, Bokeh, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n        if (Bokeh != undefined && !reloading) {\n          const NewBokeh = root.Bokeh;\n          if (Bokeh.versions === undefined) {\n            Bokeh.versions = new Map();\n          }\n          if (NewBokeh.version !== Bokeh.version) {\n            Bokeh[NewBokeh.version] = NewBokeh;\n            Bokeh.versions.set(NewBokeh.version, NewBokeh);\n          }\n          root.Bokeh = Bokeh;\n        }\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='e9011e55-1c07-4929-9093-85bb793b02ac'>\n",
       "  <div id=\"d3a0b58e-d8d0-4196-b254-0b65ad03f48f\" data-root-id=\"e9011e55-1c07-4929-9093-85bb793b02ac\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"0ea06077-0f29-4225-96aa-32dcf2cc4b22\":{\"version\":\"3.8.2\",\"title\":\"Bokeh Application\",\"config\":{\"type\":\"object\",\"name\":\"DocumentConfig\",\"id\":\"960e9688-dc60-4bfb-8bd8-352c3a203dfb\",\"attributes\":{\"notifications\":{\"type\":\"object\",\"name\":\"Notifications\",\"id\":\"2339189f-42e4-496b-a063-1504d64b794b\"}}},\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"e9011e55-1c07-4929-9093-85bb793b02ac\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"109bdb17-c00a-4215-930c-7208bc49e537\",\"attributes\":{\"plot_id\":\"e9011e55-1c07-4929-9093-85bb793b02ac\",\"comm_id\":\"cbe26c0bbe2442c6bf58b09387e7b3e2\",\"client_comm_id\":\"666b1528a373475489f08f34735fc8a0\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"start\",\"kind\":\"Any\",\"default\":0},{\"name\":\"end\",\"kind\":\"Any\",\"default\":100},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"holoviews.plotting.bokeh.raster.HoverModel\",\"properties\":[{\"name\":\"xy\",\"kind\":\"Any\",\"default\":null},{\"name\":\"data\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"0ea06077-0f29-4225-96aa-32dcf2cc4b22\",\"roots\":{\"e9011e55-1c07-4929-9093-85bb793b02ac\":\"d3a0b58e-d8d0-4196-b254-0b65ad03f48f\"},\"root_ids\":[\"e9011e55-1c07-4929-9093-85bb793b02ac\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(version);\n",
       "    } else if (root.Bokeh.version === version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "e9011e55-1c07-4929-9093-85bb793b02ac"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "<div class=\"logo-block\">\n",
       "<a href=\"https://holoviews.org\" target=\"_blank\" title=\"HoloViews 1.22.1\">\n",
       "  <img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC' style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "</a>\n",
       "\n",
       "\n",
       "<a href=\"https://bokeh.org\" target=\"_blank\" title=\"Bokeh 3.8.2\">\n",
       "  <img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACMAAAAjCAYAAAAe2bNZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAK6wAACusBgosNWgAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAf9SURBVFiFvZh7cFTVHcc/59y7793sJiFAwkvAYDRqFWwdraLVlj61diRYsDjqCFbFKrYo0CltlSq1tLaC2GprGIriGwqjFu10OlrGv8RiK/IICYECSWBDkt3s695zTv9IAtlHeOn0O7Mzu797z+/3Ob/z+p0VfBq9doNFljuABwAXw2PcvGHt6bgwxhz7Ls4YZNVXxxANLENwE2D1W9PAGmAhszZ0/X9gll5yCbHoOirLzmaQs0F6F8QMZq1v/8xgNm7DYwwjgXJLYL4witQ16+sv/U9HdDmV4WrKw6B06cZC/RMrM4MZ7xz61DAbtzEXmAvUAX4pMOVecg9/MFFu3j3Gz7gQBLygS2RGumBkL0cubiFRsR3LzVBV1UMk3IrW73PT9C2lYOwhQB4ClhX1AuKpjLcV27oEjyUpNUJCg1CvcejykWTCXyQgzic2HIIBjg3pS6+uRLKAhumZvD4U+tq0jTrgkVKQQtLekfTtxIPAkhTNF6G7kZm7aPp6M9myKVQEoaYaIhEQYvD781DML/RfBGNZXAl4irJiwBa07e/y7cQnBaJghIX6ENl2GR/fGCBoz6cm5qeyEqQA5ZYA5x5eeiV0Qph4gjFAUSwAr6QllQgcxS/Jm25Cr2Tmpsk03XI9NfI31FTZBEOgVOk51adqDBNPCNPSRlkiDXbBEwOU2WxH+I7itQZ62g56OjM33suq1YsZHVtGZSUI2QdyYgkgOthQNIF7BIGDnRAJgJSgj69cUx1gB8PkOGwL4E1gPrM27gIg7NlGKLQApc7BmEnAxP5g/rw4YqBrCDB5xHkw5rdR/1qTrN/hKNo6YUwVDNpFsnjYS8RbidBPcPXFP6R6yfExuOXmN4A3jv1+8ZUwgY9D2OWjUZE6lO88jDwHI8ZixGiMKSeYTBamCoDk6kDAb6y1OcH1a6KpD/fZesoFw5FlIXAVCIiH4PxrV+p2npVDToTBmtjY8t1swh2V61E9KqWiyuPEjM8dbfxuvfa49Zayf9R136Wr8mBSf/T7bNteA8zwaGEUbFpckWwq95n59dUIywKl2fbOIS5e8bWSu0tJ1a5redAYfqkdjesodFajcgaVNWhXo1C9SrkN3Usmv3UMJrc6/DDwkwEntkEJLe67tSLhvyzK8rHDQWleve5CGk4VZEB1r+5bg2E2si+Y0QatDK6jUVkX5eg2YYlp++ZM+rfMNYamAj8Y7MAVWFqaR1f/t2xzU4IHjybBtthzuiAASqv7jTF7jOqDMAakFHgDNsFyP+FhwZHBmH9F7cutIYkQCylYYv1AZSqsn1/+bX51OMMjPSl2nAnM7hnjOx2v53YgNWAzHM9Q/9l0lQWPSCBSyokAtOBC1Rj+w/1Xs+STDp4/E5g7Rs2zm2+oeVd7PUuHKDf6A4r5EsPT5K3gfCnBXNUYnvGzb+KcCczYYWOnLpy4eOXuG2oec0PBN8XQQAnpvS35AvAykr56rWhPBiV4MvtceGLxk5Mr6A1O8IfK7rl7xJ0r9kyumuP4fa0lMqTBLJIAJqEf1J3qE92lMBndlyfRD2YBghHC4hlny7ASqCeWo5zaoDdIWfnIefNGTb9fC73QDfhyBUCNOxrGPSUBfPem9us253YTV+3mcBbdkUYfzmHiLqZbYdIGHHON2ZlemXouaJUOO6TqtdHEQuXYY8Yt+EbDgmlS6RdzkaDTv2P9A3gICiq93sWhb5mc5wVhuU3Y7m5hOc3So7qFT3SLgOXHb/cyOfMn7xROegoC/PTcn3v8gbKPgDopJFk3R/uBPWQiwQ+2/GJevRMObLUzqe/saJjQUQTTftEVMW9tWxPgAocwcj9abNcZe7s+6t2R2xXZG7zyYLp8Q1PiRBBHym5bYuXi8Qt+/LvGu9f/5YDAxABsaRNPH6Xr4D4Sk87a897SOy9v/fKwjoF2eQel95yDESGEF6gEMwKhLwKus3wOVjTtes7qzgLdXTMnNCNoEpbcrtNuq6N7Xh/+eqcbj94xQkp7mdKpW5XbtbR8Z26kgMCAf2UU5YEovRUVRHbu2b3vK1UdDFkDCyMRQxbpdv8nhKAGIa7QaQedzT07fFPny53R738JoVYBdVrnsNx9XZ9v33UeGO+AA2MMUkgqQ5UcdDLZSFeVgONnXeHqSAC5Ew1BXwko0D1Zct3dT1duOjS3MzZnEUJtBuoQAq3SGOLR4ekjn9NC5nVOaYXf9lETrUkmOJy3pOz8OKIb2A1cWhJCCEzOxU2mUPror+2/L3yyM3pkM7jTjr1nBOgkGeyQ7erxpdJsMAS9wb2F9rzMxNY1K2PMU0WtZV82VU8Wp6vbKJVo9Lx/+4cydORdxCCQ/kDGTZCWsRpLu7VD7bfKqL8V2orKTp/PtzaXy42jr6TwAuisi+7JolUG4wY+8vyrISCMtRrLKWpvjAOqx/QGhp0rjRo5xD3x98CWQuOQN8qumRMmI7jKZPUEpzNVZsj4Zbaq1to5tZZsKIydLWojhIXrJnES79EaOzv3du2NytKuxzJKAA6wF8xqEE8s2jo/1wd/khslQGxd81Zg62Bbp31XBH+iETt7Y3ELA0iU6iGDlQ5mexe0VEx4a3x8V1AaYwFJgTiwaOsDmeK2J8nMUOqsnB1A+dcA04ucCYt0urkjmflk9iT2v30q/gZn5rQPvor4n9Ou634PeBzoznes/iot/7WnClKoM/+zCIjH5kwT8ChQjTHPIPTjFV3PpU/Hx+DM/A9U3IXI4SPCYAAAAABJRU5ErkJggg=='\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'>\n",
       "  </img>\n",
       "</a>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"float: left; margin-left: 5px; line-height: 15px; cursor: pointer; opacity: 0.7;\"\n",
       "      onmouseover=\"this.style.opacity='1'\"\n",
       "      onmouseout=\"this.style.opacity='0.7'\"\n",
       "      title=\"Extension loaded. This cell output contains code that enables plot interactivity, it should not be removed.\"></span>\n",
       "</div>\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae3002a55bd4599aff7f351395cad92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'39805e8d-4bc7-46ae-b62d-accef8a1d3ce': {'version"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = h.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyrax311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
