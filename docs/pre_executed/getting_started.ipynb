{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa8e2fbb",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "This notebook uses Hyrax to train a small convolutional neural network to classify CIFAR data<sup>1</sup>.\n",
    "It is based on the PyTorch example here: https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "In the interest of clarity, we will not perfectly reproduce the work in the PyTorch version, but we will still see the same results.\n",
    "We will note where to make configuration changes in order to be perfectly faithful to the PyTorch version.\n",
    "\n",
    "<sup>1</sup>[Learning multiple layers of features from tiny images](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf) Alex Krizhevsky, 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2437dc14",
   "metadata": {},
   "source": [
    "## Install Hyrax\n",
    "\n",
    "Before we begin we'll need to install hyrax.\n",
    "You can skip this step if you've running locally and have already installed Hyrax in your virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f61197",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install hyrax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d10408f",
   "metadata": {},
   "source": [
    "## Create a hyrax instance\n",
    "\n",
    "The main driver for Hyrax is the ``Hyrax`` class. To get started we'll create an instance of this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14731603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyrax import Hyrax\n",
    "\n",
    "h = Hyrax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf17edb",
   "metadata": {},
   "source": [
    "## Specify a model\n",
    "\n",
    "We'll need to let Hyrax know which model to use for training.\n",
    "Here we’ll tell Hyrax to use the built-in HyraxCNN model that is based on the \n",
    "[simple CNN architecture](https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-convolutional-neural-network)\n",
    "from the PyTorch CIFAR10 tutorial.\n",
    "The Hyrax version of the model class is available on GitHub [here](https://github.com/lincc-frameworks/hyrax/blob/main/src/hyrax/models/hyrax_cnn.py).\n",
    "\n",
    "Note: For a more faithful reproduction of the PyTorch example there are a few additional configuration parameters that can be set,\n",
    "however we generally omit these both for clarity and because the default values reproduce the PyTorch results well:\n",
    "```python\n",
    "h.set_config(\"data_loader.batch_size\", 4)  # Train with 4 data samples per batch\n",
    "h.set_config(\"data_set.train_split\", 1.0)  # Use all of the training data for training\n",
    "h.set_config(\"data_set.validate_split\", 0.0)  # Do not use any training data for validation\n",
    "h.set_config(\"data_set.test_split\", 0.0)  # Or for testing\n",
    "h.set_config(\"'torch.optim.SGD'.lr\", 0.001)  # Set the learning rate lower than the Hyrax default\n",
    "h.set_config(\"train.epochs\", 2)  # Only train for 2 epochs (instead of the default 10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad46942",
   "metadata": {},
   "outputs": [],
   "source": [
    "h.set_config(\"model.name\", \"HyraxCNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63286ee3",
   "metadata": {},
   "source": [
    "## Defining the dataset\n",
    "\n",
    "We’ll also need to tell Hyrax what data should be used for training, in this case the CIFAR10 dataset.\n",
    "Hyrax has a built in dataset class for working with CIFAR10 data, so we’ll configure that here.\n",
    "You can learn more about the CIFAR10 at the offical site: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "This may appear overly verbose, especially for a simple case, but being explicit about the dataset configuration will allow for great flexibility down the line when working with more complex data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_request_definition = {\n",
    "    \"train\": {\n",
    "        \"data\": {\n",
    "            \"dataset_class\": \"HyraxCifarDataset\",\n",
    "            \"data_location\": \"./data\",\n",
    "            \"fields\": [\"image\", \"label\"],\n",
    "            \"primary_id_field\": \"object_id\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "h.set_config(\"data_request\", data_request_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27957986",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "With the model and data specified,we're ready for training.\n",
    "We'll use the ``train`` verb to kick off the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cddb17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = h.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0608a5",
   "metadata": {},
   "source": [
    "The output of training will be stored in a timestamped directory with a name similar to `.../YYYYmmdd-HHMMSS-train-xxxx/`.\n",
    "This output directory will contain the saved model weights, full configuration, checkpoints, and any other information necessary to reproduce the work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55f1b9f",
   "metadata": {},
   "source": [
    "## Predicting with the model\n",
    "\n",
    "Now that we've trained a model, we can use it to infer classes of samples from the CIFAR10 test dataset.\n",
    "First we'll add to our model input definition to specify the data to use for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef1025",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_request_definition[\"infer\"] = {\n",
    "    \"data\": {\n",
    "        \"dataset_class\": \"HyraxCifarDataset\",\n",
    "        \"data_location\": \"./data\",\n",
    "        \"fields\": [\"image\", \"object_id\"],\n",
    "        \"primary_id_field\": \"object_id\",\n",
    "        \"dataset_config\": {\n",
    "            \"use_training_data\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "h.config[\"data_request\"] = data_request_definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57812f58",
   "metadata": {},
   "source": [
    "Then we'll use Hyrax's ``infer`` verb to load the trained model weights and predict the classes of the data defined in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aae867",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_results = h.infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff6f807",
   "metadata": {},
   "source": [
    "## Evaluating the performance\n",
    "\n",
    "Let's compare the models predictions to the actual labels from the test dataset.\n",
    "The model's prediction is a 10 element vector where the largest value represents the highest confidence class.\n",
    "So we'll extract the index of the max value for each prediction and save that as `predicted_classes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ebe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index of the maximum predicted class for all test samples\n",
    "import numpy as np\n",
    "\n",
    "predicted_classes = np.zeros(len(inference_results)).astype(int)\n",
    "for i in range(len(inference_results)):\n",
    "    predicted_classes[i] = inference_results[i].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48911d11",
   "metadata": {},
   "source": [
    "We'll also load the original test data to get access to the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f691f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./data/cifar-10-batches-py/test_batch\", \"rb\") as f_in:\n",
    "    test_data = pickle.load(f_in, encoding=\"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad332b6f",
   "metadata": {},
   "source": [
    "Finally we'll print the overall accuracy and use scikit-learn's ``confusion_matrix`` to display a nice confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "y_true = test_data[b\"labels\"]\n",
    "y_pred = predicted_classes.tolist()\n",
    "\n",
    "correct = 0\n",
    "for t, p in zip(y_true, y_pred):\n",
    "    correct += t == p\n",
    "\n",
    "print(\"\\nAccuracy for test dataset:\", correct / len(y_true))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e52be7",
   "metadata": {},
   "source": [
    "The overall accuracy is around 50% - significantly better than random which would be 10%.\n",
    "Accuracy of ~50% is in agreement with the [PyTorch example results](https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#test-the-network-on-the-test-data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyrax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
